\cvsection{Selected Publications}
% Give this section a touch more breathing room. The previous
% negative vspace compressed it too much and left extra whitespace
% at the bottom of page 2 once other sections were adjusted.

\begin{cvparagraph}
  For the complete list of publications, visit \href{https://scholar.google.com/citations?user=lRxoOlwAAAAJ}{Google Scholar}.
\end{cvparagraph}

{\footnotesize
% Publications use compact two-row tabular blocks (authors/title and venue/year).
% Slightly increase the row spacing so entries breathe and the section
% cleanly fills the second page without awkward bottom whitespace.
\providecommand{\pubarraystretch}{1.16}% tuning knob
\renewcommand{\arraystretch}{\pubarraystretch}% was 1.0
% Add a hair of vertical space before each \cventry locally (class already
% applies a tiny negative space). Etotoolbox is loaded by the class.
\providecommand{\pubentryvspace}{0.35mm}% tuning knob
\pretocmd{\cventry}{\vspace{\pubentryvspace}}{}{}
\cvsubsection{Transformers \& Distillation}
\vspace{0.8mm}
\begin{cventries}
  \cventry
    {\textbf{Cenk Baykal}, Dylan Cutler, Nishanth Dikkala, Nikhil Ghosh, Rina Panigrahy, Xin Wang}
    {Alternating Updates for Efficient Transformers}
    {NeurIPS (Spotlight)}
    {2023}
    {}

  \cventry
    {Vasilis Kontonis, Fotis Iliopoulos, Khoa Trinh, \textbf{Cenk Baykal}, Gaurav Menghani, Erik Vee}
    {SLaM: Student-Label Mixing for Distillation with Unlabeled Examples}
    {NeurIPS}
    {2023}
    {}

  \cventry
    {\textbf{Cenk Baykal}, Khoa Trinh, Fotis Iliopoulos, Gaurav Menghani, Erik Vee}
    {Robust Active Distillation}
    {ICLR}
    {2023}
    {}

  \cventry
    {\textbf{Cenk Baykal}, Nishanth Dikkala, Rina Panigrahy, Cyrus Rashtchian, Xin Wang}
    {A Theoretical View on Sparsely Activated Networks}
    {NeurIPS}
    {2022}
    {}
\end{cventries}

\cvsubsection{Compression \& Robotics}
\vspace{0.8mm}
\begin{cventries}
  \cventry
    {\textbf{Cenk Baykal}*, Lucas Liebenwein*, Igor Gilitschenski, Dan Feldman, Daniela Rus}
    {SiPPing Neural Networks: Sensitivity-informed Provable Pruning of Neural Networks}
    {SIAM SIMODS}
    {2022}
    {}

  \cventry
    {Lucas Liebenwein, \textbf{Cenk Baykal}, Brandon Carter, David Gifford, Daniela Rus}
    {Lost in Pruning: The Effects of Pruning Neural Networks beyond Test Accuracy}
    {MLSys}
    {2021}
    {}

  \cventry
    {\textbf{Cenk Baykal}*, Lucas Liebenwein*, Harry Lang, Dan Feldman, Daniela Rus}
    {Provable Filter Pruning for Efficient Neural Networks}
    {ICLR}
    {2020}
    {}

  \cventry
    {\textbf{Cenk Baykal}*, Lucas Liebenwein*, Igor Gilitschenski, Dan Feldman, Daniela Rus}
    {Data-Dependent Coresets for Compressing Neural Networks with Applications to Generalization Bounds}
    {ICLR}
    {2019}
    {}

  \cventry
    {\textbf{Cenk Baykal}*, Lucas Liebenwein*, Igor Gilitschenski, Sertac Karaman, Daniela Rus}
    {Sampling-Based Approximation Algorithms for Reachability Analysis with Provable Guarantees}
    {RSS}
    {2018}
    {}

  \cventry
    {\textbf{Cenk Baykal}, Ron Alterovitz}
    {Asymptotically Optimal Design of Piecewise Cylindrical Robots using Motion Planning}
    {RSS (Best Paper Award)}
    {2017}
    {}
\end{cventries}
}
